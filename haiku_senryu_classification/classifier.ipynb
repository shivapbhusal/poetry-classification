{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import statistics\n",
    "\n",
    "# Load the pre-trained Word2Vec model (about 3.6 GB in size)\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stop_word(word):\n",
    "    stop_word_list = [\n",
    "    'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', \n",
    "    'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', \n",
    "    'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', \n",
    "    'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', \n",
    "    'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', \n",
    "    'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', \n",
    "    'such', 'no', 'nor', 'not', 'only', 'same', 'so', 'than', 'too', \n",
    "    'very', 's', 't', 'can', 'will', 'just', 'should', 'now', 'without', 'with']\n",
    "    \n",
    "    return word in stop_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_word(word):\n",
    "    cleaned_up_word = word.replace(\".\", \"\").replace(\"-\", \"\")\n",
    "    return cleaned_up_word.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seasonality_score(poem):\n",
    "    poem_words = poem.split()\n",
    "    # https://mainichi.jp/english/articles/20210531/p2a/00m/0su/032000c\n",
    "    season_words = ['winter', 'spring', 'summer','autumn']\n",
    "    seasonality_score = -1\n",
    "    for raw_word in poem_words:\n",
    "        word = cleanup_word(raw_word)\n",
    "        for season_word in season_words:\n",
    "            if word in model and season_word in model and not is_stop_word(word):\n",
    "                cosine_similarity = model.similarity(word, season_word)\n",
    "                seasonality_score = max(cosine_similarity, seasonality_score)\n",
    "    return seasonality_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_human_reference_score(poem):\n",
    "    poem_words = poem.split()\n",
    "    me_words = ['i', 'me', 'my','mine', 'he','she',\n",
    "                'they','our','his','her','him','their','we']\n",
    "    human_reference_scores = []\n",
    "    for raw_word in poem_words:\n",
    "        word = cleanup_word(raw_word)\n",
    "        max_similarity = 0\n",
    "        for me_word in me_words:\n",
    "            if word in model and me_word in model and not is_stop_word(word):\n",
    "                max_similarity = max(max_similarity, model.similarity(word, me_word))\n",
    "        human_reference_scores.append(max_similarity)\n",
    "    return statistics.mean(human_reference_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_natureness_score(poem):\n",
    "    poem_words = poem.split()\n",
    "    nature_words = ['nature', 'wild', 'bird', 'tree', 'river', 'leaf',\n",
    "                    'mountain', 'flower','plant', 'wind', 'rain', 'forest']\n",
    "    natureness_scores = []\n",
    "    for raw_word in poem_words:\n",
    "        word = cleanup_word(raw_word)\n",
    "        for nature_word in nature_words:\n",
    "            if word in model and nature_word in model and not is_stop_word(word):\n",
    "                cosine_similarity = model.similarity(word, nature_word)\n",
    "                natureness_scores.append(cosine_similarity)\n",
    "    return statistics.mean(natureness_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average(word_vectors):\n",
    "    sums = [0] * len(word_vectors[0])\n",
    "    \n",
    "    for word_vector in word_vectors:\n",
    "        for i in range(len(word_vector)):\n",
    "            sums[i] += word_vector[i]\n",
    "    return [total/len(word_vectors) for total in sums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_get_average_vector(poem):\n",
    "    words = poem.split()\n",
    "    word_vectors = []\n",
    "    for word in words:\n",
    "        processed_word = cleanup_word(word)\n",
    "        if processed_word in model and not is_stop_word(processed_word):\n",
    "            word_vectors.append(model[processed_word])\n",
    "            \n",
    "    return get_average(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "# Humor detection\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a text generation model\n",
    "detect_humor = pipeline(model=\"shivapbhusal/haiku_humor\",task=\"sentiment-analysis\",tokenizer=\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes_for_all_poems(data_file):\n",
    "    with open(data_file, 'r') as file:\n",
    "        data = file.read()\n",
    "\n",
    "    poems = [poem.strip() for poem in data.split('\\n\\n') if poem.strip()]\n",
    "    attributes = [] # List of dictionaries.\n",
    "    for poem in poems:\n",
    "        poem_one_liner = \" \".join(poem.splitlines())\n",
    "        poem_one_liner = poem_one_liner.lower()\n",
    "        # Get Humor Score\n",
    "        humor_content = detect_humor(poem_one_liner)\n",
    "        humor_score = humor_content[0][\"score\"] if humor_content[0][\"label\"] else 1 - humor_content[0][\"score\"]\n",
    "        \n",
    "        #Get Natureness Score\n",
    "        natureness_score = get_natureness_score(poem_one_liner)\n",
    "        \n",
    "        #Get Seasonality Score\n",
    "        seasonality_score = get_seasonality_score(poem_one_liner)\n",
    "        \n",
    "        #Get Human Reference Score\n",
    "        self_score = get_human_reference_score(poem_one_liner)\n",
    "        \n",
    "        # Get General Score\n",
    "        average_vector = split_and_get_average_vector(poem_one_liner)\n",
    "        \n",
    "        attributes.append({\"poem\": poem_one_liner,\n",
    "                           \"humor_score\": humor_score,\n",
    "                           \"natureness_score\": natureness_score,\n",
    "                           \"seasonality_score\": seasonality_score,\n",
    "                           \"human_reference_score\": self_score,\n",
    "                           \"average_vector\": average_vector})\n",
    "    return attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "senryu_data = get_attributes_for_all_poems('data/senryu.txt')\n",
    "haiku_data = get_attributes_for_all_poems('data/haiku.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 75.98425196850394%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       252\n",
      "           1       0.77      0.75      0.76       256\n",
      "\n",
      "    accuracy                           0.76       508\n",
      "   macro avg       0.76      0.76      0.76       508\n",
      "weighted avg       0.76      0.76      0.76       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "import warnings\n",
    "\n",
    "# To suppress the warning and show only relevant messages\n",
    "warnings.simplefilter('ignore', FitFailedWarning)\n",
    "\n",
    "# Prepare your data\n",
    "senryu_metrics = [[attribute[\"humor_score\"],\n",
    "                  attribute[\"natureness_score\"],\n",
    "                  attribute[\"seasonality_score\"],\n",
    "                  attribute[\"human_reference_score\"]] + attribute[\"average_vector\"] for attribute in senryu_data]\n",
    "                  \n",
    "haiku_metrics = [[attribute[\"humor_score\"],\n",
    "                  attribute[\"natureness_score\"],\n",
    "                  attribute[\"seasonality_score\"],\n",
    "                  attribute[\"human_reference_score\"]] + attribute[\"average_vector\"] for attribute in haiku_data]\n",
    "\n",
    "training_set = senryu_metrics + haiku_metrics\n",
    "labels = [0] * len(senryu_metrics) + [1] * len(haiku_metrics)  # 0 for senryu, 1 for haiku\n",
    "\n",
    "# Split the data into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_set, labels, test_size=0.2, random_state=43)\n",
    "\n",
    "# Define the parameter grid with conditional parameters\n",
    "param_grid = [\n",
    "    {'kernel': ['linear'], 'C': [0.1, 1, 10, 100]},\n",
    "    {'kernel': ['rbf'], 'C': [0.1, 1, 10, 100], 'gamma': ['scale', 'auto']},\n",
    "    {'kernel': ['poly'], 'C': [0.1, 1, 10, 100], 'degree': [2, 3, 4], 'gamma': ['scale', 'auto']},\n",
    "    {'kernel': ['sigmoid'], 'C': [0.1, 1, 10, 100], 'gamma': ['scale', 'auto']}\n",
    "]\n",
    "\n",
    "# Set up the SVM model\n",
    "svc = svm.SVC(probability=True)\n",
    "\n",
    "# Apply GridSearchCV\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Train the model using Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and classifier\n",
    "best_params = grid_search.best_params_\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Accuracy: {accuracy * 100}%\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 0 1 0]\n",
      "Probabilities: [[0.19117294 0.80882706]\n",
      " [0.88964181 0.11035819]\n",
      " [0.26385553 0.73614447]\n",
      " [0.84589984 0.15410016]]\n",
      "[[0.022747457027435303, 0.16689484, 0.46266505, 0.10701379], [0.9091053009033203, 0.09049404, 0.36718187, 0.27351004], [0.022456109523773193, 0.14482306, 1.0, 0.08248165], [0.22774267196655273, 0.069834016, 0.3275469, 0.32577872]]\n"
     ]
    }
   ],
   "source": [
    "poem_kerouac = \"birds singing in the dark -- rainy dawn\"\n",
    "poem_rotella = \"She running for office — for the first time my neighbor waves\"\n",
    "poem_virgilio = \"autumn twilight:the wreath on the door lifts in the wind\"\n",
    "poem_swede = \"alone at last i wonder where everyone is\"\n",
    "\n",
    "poems = [poem_kerouac, poem_rotella, poem_virgilio, poem_swede]\n",
    "attributes = []\n",
    "\n",
    "for poem in poems:\n",
    "    poem_one_liner = poem.lower()\n",
    "    \n",
    "    # Get Humor Score\n",
    "    humor_content = detect_humor(poem_one_liner)\n",
    "    humor_score = humor_content[0][\"score\"] if humor_content[0][\"label\"] else 1 - humor_content[0][\"score\"]\n",
    "        \n",
    "    # Get Natureness Score\n",
    "    natureness_score = get_natureness_score(poem_one_liner)\n",
    "        \n",
    "    # Get Seasonality Score\n",
    "    seasonality_score = get_seasonality_score(poem_one_liner)\n",
    "        \n",
    "    # Get Human Reference Score\n",
    "    human_reference_score = get_human_reference_score(poem_one_liner)\n",
    "        \n",
    "    # Get General Score\n",
    "    average_vector = split_and_get_average_vector(poem_one_liner)\n",
    "        \n",
    "    attributes.append([humor_score, natureness_score, seasonality_score, human_reference_score] + average_vector)\n",
    "\n",
    "# Predict class labels\n",
    "prediction = best_clf.predict(attributes)\n",
    "\n",
    "# Predict probabilities (percentage likelihood for each class)\n",
    "probabilities = best_clf.predict_proba(attributes)\n",
    "\n",
    "# Print predictions and probabilities\n",
    "print(\"Predictions:\", prediction)\n",
    "print(\"Probabilities:\", probabilities)\n",
    "print([attribute[0:4] for attribute in attributes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
